# ğŸ§ Sound Classifier Project: MobileNetV2 for Environmental Sound Classification

## ğŸš€ Projet DÃ©ployÃ©

**Ceci est le code source du classificateur de sons dÃ©ployÃ© gratuitement sur Hugging Face Spaces.**

| Application en Ligne | DÃ©mo |
| :--- | :--- |
| [Lien vers votre Space Hugging Face](https://huggingface.co/spaces/Nebrass1/sound-classifier-nebrass) | **** |

## ğŸ¯ Objectif du Projet

Ce projet vise Ã  dÃ©velopper un classificateur capable d'identifier automatiquement des sons environnementaux (ex. : chien, pluie, klaxon) Ã  partir de courts clips audio.

La solution utilise une approche de **Computer Vision** : les signaux audio sont convertis en **Spectrogrammes Mel**, transformant le problÃ¨me d'analyse audio en un problÃ¨me de classification d'images.

## ğŸ§  Architecture et MÃ©thode

Nous avons utilisÃ© une approche de **Transfer Learning** basÃ©e sur un modÃ¨le de classification d'images prÃ©-entraÃ®nÃ©, ce qui permet d'obtenir une bonne prÃ©cision malgrÃ© un dataset d'entraÃ®nement rÃ©duit.

### Composants ClÃ©s

1.  **PrÃ©-traitement Audio:** Utilisation de la librairie **Librosa** pour transformer les fichiers audio bruts en images de **spectrogrammes Mel**.
2.  **ModÃ¨le de Base:** **MobileNetV2** (prÃ©-entraÃ®nÃ© sur ImageNet). Ce modÃ¨le est idÃ©al pour les images de petite taille comme les spectrogrammes.
3.  **Transfer Learning:** Le modÃ¨le est entraÃ®nÃ© en deux phases (couches gelÃ©es, puis Fine-Tuning) pour affiner les poids de MobileNetV2 Ã  la reconnaissance des caractÃ©ristiques visuelles spÃ©cifiques des spectrogrammes.

### Performance

AprÃ¨s l'entraÃ®nement complet (Transfer Learning et Fine-Tuning), le modÃ¨le a atteint une prÃ©cision de validation (validation accuracy) de **87.50%**.

## ğŸ› ï¸ Utilisation et Installation

### PrÃ©requis

* Python 3.8+
* Git et Git LFS (Git Large File Storage)

### Structure du Projet
â”œâ”€â”€ app.py # Script de l'interface Gradio et de la logique de prÃ©diction.
â”œâ”€â”€ train_model.py # Script d'entraÃ®nement MobileNetV2 (Transfer Learning).
â”œâ”€â”€ requirements.txt # DÃ©pendances Python.
â”œâ”€â”€ sound_classifier_model.h5 # ModÃ¨le Keras entraÃ®nÃ© (stockÃ© via Git LFS).
â””â”€â”€ class_labels.json # Mapping des classes (ex: {"dog": 0, "rain": 1, ...}).


### DÃ©marrage Local de l'Application

Pour lancer l'interface web Gradio localement :

1.  **Installer les dÃ©pendances :**
    ```bash
    pip install -r requirements.txt
    ```
2.  **Lancer l'Application :**
    ```bash
    python app.py
    ```
    *(Le modÃ¨le doit Ãªtre prÃ©sent dans le dossier racine.)*